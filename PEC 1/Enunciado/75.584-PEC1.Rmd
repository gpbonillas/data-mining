---
title: 'Minería de datos: PEC1'
author: "Autor: Nombre estudiante"
date: "Octubre 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******
## Presentación
Esta prueba de evaluación continuada cubre el módulo 1,2 y 8 del programa de la asignatura.  

## Competencias
Las competencias que se trabajan en esta prueba son:

* Uso y aplicación de las TIC en el ámbito académico y profesional
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes, así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.
* Capacidad de utilizar un lenguaje de programación.  
* Capacidad para desarrollar en una herramienta IDE.  
* Capacidad de plantear un proyecto de minería de datos.  

## Objetivos
* Asimilar correctamente el módulo 1 y 2.
*	Qué es y qué no es MD.
*	Ciclo de vida de los proyectos de MD.
*	Diferentes tipologías de MD.
* Conocer las técnicas propias de una fase de preparación de datos y objetivos a alcanzar.  

## Descripción de la PEC a realizar
La prueba está estructurada en 1 ejercicio teórico/práctico y 1 ejercicio práctico que pide que se desarrolle la fase de preparación en un juego de datos.  
Deben responderse todos los ejercicios para poder superar la PEC.  

## Recursos
Para realizar esta práctica recomendamos la lectura de los siguientes documentos:  

* Módulo 1, 2 y 8 del material didáctico.  
* RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  
* R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada apartado del ejercicio práctico qué se ha hecho y cómo se ha hecho.  

## Formato y fecha de entrega
El formato de entrega es: usernameestudiant-PECn.html y rmd  
Fecha de Entrega: 28/10/2020  
Se debe entregar la PEC en el buzón de entregas del aula  


## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en qué se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia  no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado  
******
Como ejemplo, trabajaremos con el conjunto de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".   

De momento dejaremos para las siguientes prácticas el estudio de algoritmos predictivos y nos centraremos por ahora en el estudio de las variables de una muestra de datos, es decir, haremos un trabajo descriptivo del mismo. 

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de características o variables y la preparación del los  datos para posteriormente ser consumido por un algoritmo.

Las técnicas que trabajaremos son las siguientes:  

1. Normalización  
2. Discretización  
3. Gestión de valores nulos  
4. Estudio de correlaciones  
5. Reducción de la dimensionalidad
6. Análisis visual del conjunto de datos  

******
# Ejemplo de estudio visual con el juego de datos Titanic
******

## Procesos de limpieza del conjunto de datos

Primer contacto con el conjunto de datos, visualizamos su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)

# Cargamos el fichero de datos
totalData <- read.csv('titanic.csv',stringsAsFactors = FALSE)
filas=dim(totalData)[1]

# Verificamos la estructura del conjunto de datos
str(totalData)
```
Descripción de las variables contenidas en el fichero:

name
    a string with the name of the passenger.
    
gender
    a factor with levels male and female.
    
age
    a numeric value with the persons age on the day of the sinking. The age of babies (under 12 months) is given as a fraction of one year (1/month).
    
class
    a factor specifying the class for passengers or the type of service aboard for crew members.
    
embarked
    a factor with the persons place of of embarkment.
    
country
    a factor with the persons home country.
    
ticketno
    a numeric value specifying the persons ticket number (NA for crew members).
    
fare
    a numeric value with the ticket price (NA for crew members, musicians and employees of the shipyard company).
    
sibsp
    an ordered factor specifying the number if siblings/spouses aboard; adopted from Vanderbild data set.
    
parch
    an ordered factor specifying the number of parents/children aboard; adopted from Vanderbild data set.
    
survived
    a factor with two levels (no and yes) specifying whether the person has survived the sinking.
    

Mostramos estadísticas bàsicas y después trabajamos los atributos con valores vacíos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Estadísticas básicas
summary(totalData)

# Estadísticas de valores vacíos
colSums(is.na(totalData))
colSums(totalData=="")

# Tomamos valor "Desconocido" para los valores vacíos de la variable "country"
totalData$Embarked[totalData$country==""]="Desconocido"

# Tomamos la media para valores vacíos de la variable "Age"
totalData$Age[is.na(totalData$age)] <- mean(totalData$age,na.rm=T)
```

Discretizamos cuando tiene sentido y en función de las capacidades de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Añadimos una variable nueva a los datos. Este valor es la edad discretizada con un método simple de intervalos de igual amplitud.
# Vemos cómo se distribuyen los valore
summary(totalData[,"age"])
# Discretizamos
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
# Observamos los datos discretizados.
head(totalData)
# Vemos como se agrupan los datos.
plot(totalData$segmento_edad)
```


## Procesos de análisis del conjunto de datos

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "survival":
ggplot(data=totalData[1:filas,],aes(x=gender,fill=survived))+geom_bar()

# Otro punto de vista. Survival como función de Embarked:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

En la primera gráfica podemos observar fácilmente la cantidad de mujeres que viajaban respecto hombres y observar los que no sobrevivieron. Numéricamente el número de hombres y mujeres supervivientes es similar.

En la segunda gráfica de forma porcentual observamos los puertos de embarque y los porcentajes de supervivencia en función del puerto. Se podría trabajar el puerto C (Cherburgo) para ver de explicar la diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o niños... O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 56.45%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$embarked,totalData[1:filas,]$survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se podría hacer un gráfico similar trabajando solo la clase. Habría que unificar toda la tripulación a una única categoría.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth =1,position="fill")+ylab("Frecuencia")

  
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```



******
# Ejercicios
******

## Ejercicio 1: 

Estudia los tres casos siguientes y contesta, de forma razonada la pregunta que se realiza:

* Disponemos de un conjunto de variables referentes a vehículos, tales como la marca, modelo, año de matriculación, etc. También se dispone del precio al que se vendieron. Al poner a la venta a un nuevo vehículo, se dispone de las variables que lo describen, pero se desconoce el precio. ¿Qué tipo de algoritmo se debería aplicar para predecir de forma automática el precio?

* En un almacén de naranjas se tiene una máquina, que de forma automática obtiene un conjunto de variables de cada naranja, como su tamaño, acidez, grado maduración, etc. Si se desea estudiar las naranjas por tipos, según las variables obtenidas, ¿qué tipo de algoritmo es el más adecuado?

* Un servicio de música por internet dispone de los historiales de audición de sus clientes: Qué canciones y qué grupos eligen los clientes a lo largo del tiempo de sus escuchas. La empresa desea crear un sistema  que proponga la siguiente canción y grupo en función de la canción que se ha escuchado antes. ¿Qué tipo de algoritmo es el más adecuado?

### Respuesta 1:
> Escribe aquí la respuesta a la pregunta

## Ejercicio 2:  
A partir del conjunto de datos disponible en el siguiente enlace http://archive.ics.uci.edu/ml/datasets/Adult , realiza un estudio tomando como propuesta inicial al que se ha realizado con el conjunto de datos "Titanic". Amplia la propuesta generando nuevos indicadores o solucionando otros problemas expuestos en el módulo 2. Explica el proceso que has seguido, qué conocimiento obtienes de los datos, qué objetivo te has fijado y detalla los pasos, técnicas usadas y los problemas resueltos.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de algún repositorio open data siempre que sea similar en diversidad de tipos de variables al propuesto. 

### Respuesta 2:

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el juego de datos
#datosAdult <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',stringsAsFactors = FALSE, header = FALSE)

# Nombres de los atributos
#names(datosAdult) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hour-per-week","native-country","income")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Redacta aquí el código R para el estudio del juego de datos Adult
```
***
# Rúbrica
***
Pregunta Concepto Peso en la nota final

1ª	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1ª	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1b	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1b	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1c	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1c	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

2 Se carga la base de datos, se visualiza su estructura y se explican los hechos básicos. 5%

2 Se estudia si existen atributos vacíos, y si es el caso, se adoptan medidas para tratar estos atributos. 2.5%

2 Se transforma algún atributo para adaptarlo en un estudio posterior. 2.5%

2 Se realiza alguna discretitzación de algún atributo. 2.5%

2 Se crea un indicador nuevo a partido otros atributos 2.5%

2 Se analizan los datos de forma visual y se extraen conclusiones tangibles. Hay que elaborar un discurso coherente y con conclusiones claras. 35%

2 Se trata en profundidad algún otro aspecto respecto a los datos presentado en el módulo 2 15%

2 Se ha buscado información adicional, se ha incluido en el documento de respuesta y las fuentes se han citado correctamente 5%