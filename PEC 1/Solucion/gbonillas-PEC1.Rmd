---
title: 'Minería de datos: PEC1'
author: "Autor: Gabriel Patricio Bonilla Sanchez"
date: "Octubre 2020"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******
## Presentación
Esta prueba de evaluación continuada cubre el módulo 1,2 y 8 del programa de la asignatura.  

## Competencias
Las competencias que se trabajan en esta prueba son:

* Uso y aplicación de las TIC en el ámbito académico y profesional
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes, así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.
* Capacidad de utilizar un lenguaje de programación.  
* Capacidad para desarrollar en una herramienta IDE.  
* Capacidad de plantear un proyecto de minería de datos.  

## Objetivos
* Asimilar correctamente el módulo 1 y 2.
*	Qué es y qué no es MD.
*	Ciclo de vida de los proyectos de MD.
*	Diferentes tipologías de MD.
* Conocer las técnicas propias de una fase de preparación de datos y objetivos a alcanzar.  

## Descripción de la PEC a realizar
La prueba está estructurada en 1 ejercicio teórico/práctico y 1 ejercicio práctico que pide que se desarrolle la fase de preparación en un juego de datos.  
Deben responderse todos los ejercicios para poder superar la PEC.  

## Recursos
Para realizar esta práctica recomendamos la lectura de los siguientes documentos:  

* Módulo 1, 2 y 8 del material didáctico.  
* RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  
* R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de datos.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada apartado del ejercicio práctico qué se ha hecho y cómo se ha hecho.  

## Formato y fecha de entrega
El formato de entrega es: usernameestudiant-PECn.html y rmd  
Fecha de Entrega: 28/10/2020  
Se debe entregar la PEC en el buzón de entregas del aula  


## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en qué se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia  no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado  
******
Como ejemplo, trabajaremos con el conjunto de datos "Titanic" que recoge datos sobre el famoso crucero y sobre el que es fácil realizar tareas de clasificación predictiva sobre la variable "Survived".   

De momento dejaremos para las siguientes prácticas el estudio de algoritmos predictivos y nos centraremos por ahora en el estudio de las variables de una muestra de datos, es decir, haremos un trabajo descriptivo del mismo. 

Las actividades que llevaremos a cabo en esta práctica suelen enmarcarse en las fases iniciales de un proyecto de minería de datos y consisten en la selección de características o variables y la preparación del los  datos para posteriormente ser consumido por un algoritmo.

Las técnicas que trabajaremos son las siguientes:  

1. Normalización  
2. Discretización  
3. Gestión de valores nulos  
4. Estudio de correlaciones  
5. Reducción de la dimensionalidad
6. Análisis visual del conjunto de datos  

******
# Ejemplo de estudio visual con el juego de datos Titanic
******

## Procesos de limpieza del conjunto de datos

Primer contacto con el conjunto de datos, visualizamos su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)

# Cargamos el fichero de datos
totalData <- read.csv('titanic.csv',stringsAsFactors = FALSE)
filas=dim(totalData)[1]

# Verificamos la estructura del conjunto de datos
str(totalData)
```
Descripción de las variables contenidas en el fichero:

name
    a string with the name of the passenger.
    
gender
    a factor with levels male and female.
    
age
    a numeric value with the persons age on the day of the sinking. The age of babies (under 12 months) is given as a fraction of one year (1/month).
    
class
    a factor specifying the class for passengers or the type of service aboard for crew members.
    
embarked
    a factor with the persons place of of embarkment.
    
country
    a factor with the persons home country.
    
ticketno
    a numeric value specifying the persons ticket number (NA for crew members).
    
fare
    a numeric value with the ticket price (NA for crew members, musicians and employees of the shipyard company).
    
sibsp
    an ordered factor specifying the number if siblings/spouses aboard; adopted from Vanderbild data set.
    
parch
    an ordered factor specifying the number of parents/children aboard; adopted from Vanderbild data set.
    
survived
    a factor with two levels (no and yes) specifying whether the person has survived the sinking.
    

Mostramos estadísticas bàsicas y después trabajamos los atributos con valores vacíos.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Estadísticas básicas
summary(totalData)

# Estadísticas de valores vacíos
colSums(is.na(totalData))
colSums(totalData=="")

# Tomamos valor "Desconocido" para los valores vacíos de la variable "country"
totalData$Embarked[totalData$country==""]="Desconocido"

# Tomamos la media para valores vacíos de la variable "Age"
totalData$Age[is.na(totalData$age)] <- mean(totalData$age,na.rm=T)
```

Discretizamos cuando tiene sentido y en función de las capacidades de cada variable.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Añadimos una variable nueva a los datos. Este valor es la edad discretizada con un método simple de intervalos de igual amplitud.
# Vemos cómo se distribuyen los valores
summary(totalData[,"age"])
# Discretizamos
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
# Observamos los datos discretizados.
head(totalData)
# Vemos como se agrupan los datos.
plot(totalData$segmento_edad)
```


## Procesos de análisis del conjunto de datos

Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "survival":
ggplot(data=totalData[1:filas,],aes(x=gender,fill=survived))+geom_bar()

# Otro punto de vista. Survival como función de Embarked:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+ylab("Frecuencia")

```

En la primera gráfica podemos observar fácilmente la cantidad de mujeres que viajaban respecto hombres y observar los que no sobrevivieron. Numéricamente el número de hombres y mujeres supervivientes es similar.

En la segunda gráfica de forma porcentual observamos los puertos de embarque y los porcentajes de supervivencia en función del puerto. Se podría trabajar el puerto C (Cherburgo) para ver de explicar la diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o niños... O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 56.45%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$embarked,totalData[1:filas,]$survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se podría hacer un gráfico similar trabajando solo la clase. Habría que unificar toda la tripulación a una única categoría.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survivial como función de SibSp y Parch
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
# Vemos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas.
```

Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r echo=TRUE, message=FALSE, warning=FALSE}

# Construimos un atributo nuevo: family size.
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth=1,position="fill")+ylab("Frecuencia")
```

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.  
Observamos como el parámetro position="fill" nos da la proporción acumulada de un atributo dentro de otro

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Survival como función de age:
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frecuencia")
```



******
# Ejercicios
******

## Ejercicio 1: 

Estudia los tres casos siguientes y contesta, de forma razonada la pregunta que se realiza:

* Disponemos de un conjunto de variables referentes a vehículos, tales como la marca, modelo, año de matriculación, etc. También se dispone del precio al que se vendieron. Al poner a la venta a un nuevo vehículo, se dispone de las variables que lo describen, pero se desconoce el precio. ¿Qué tipo de algoritmo se debería aplicar para predecir de forma automática el precio?

* En un almacén de naranjas se tiene una máquina, que de forma automática obtiene un conjunto de variables de cada naranja, como su tamaño, acidez, grado maduración, etc. Si se desea estudiar las naranjas por tipos, según las variables obtenidas, ¿qué tipo de algoritmo es el más adecuado?

* Un servicio de música por internet dispone de los historiales de audición de sus clientes: Qué canciones y qué grupos eligen los clientes a lo largo del tiempo de sus escuchas. La empresa desea crear un sistema  que proponga la siguiente canción y grupo en función de la canción que se ha escuchado antes. ¿Qué tipo de algoritmo es el más adecuado?

### Respuesta 1:


* 1. Para el primer se podría aplicar cualquiera de los algoritmos supervisados, como podría ser una red neuronal con la cual podriamos, predecir el valor del precio para el coche. Es probable que deba usar varios modelos para llegar a predecir correctamente el precio de un nuevo coche, por ejemplo se me ocurre que sea conveniente predecir el valor del precio aplicando varios algoritmos, por ejemplo, pueden ser clasificados por la marca y año para finalmente aplicar el modelo que me predizca el precio. La variable año de matriculacón puede ser discretizada y usada como una clase (viejo, nuevo). En el enunciado del ejercicio claramente se define la tarea de predicción para este caso.

* 2. De igual manera al primero, se debe usar algoritmos supervisados que me permita clasificar las naranjas según las variables recogidas. La clasificación se logrará con la ayuda de etiquetas de clases definidas a partir del conjunto de variables. Para este caso el enunciado manifiesta que se desea estudiar las naranjas por tipos, es decir clasificarlas por tipos. El conjunto de variables que se obtienen de manera automática para cada naranja serviría para determinar la clase o tipo a la que pertenece.


* 3. En el tercer caso se aplica un modelo no supervisado, ya que la predicción se hace según la última canción escuchada, no se tiene un conjunto de variables para este caso,  que permita clasificarla, aún cuando se guarde el historial de canciones y grupos escuchados por los usuarios. En este caso se bosca la predicción de la siguiente canción a reproducir en base a la similitud con la canción anterior, ya que se trata de obtener una descripción inicial que separe grupos de objetos con características parecidas.


## Ejercicio 2:  
A partir del conjunto de datos disponible en el siguiente enlace http://archive.ics.uci.edu/ml/datasets/Adult , realiza un estudio tomando como propuesta inicial al que se ha realizado con el conjunto de datos "Titanic". Amplia la propuesta generando nuevos indicadores o solucionando otros problemas expuestos en el módulo 2. Explica el proceso que has seguido, qué conocimiento obtienes de los datos, qué objetivo te has fijado y detalla los pasos, técnicas usadas y los problemas resueltos.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de algún repositorio open data siempre que sea similar en diversidad de tipos de variables al propuesto. 

### Respuesta 2:

#### Se carga la base de datos, se visualiza su estructura y se explican los hecho básicos

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el juego de datos
datosAdult <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', strip.white = TRUE, sep = ",", stringsAsFactors = FALSE, header = FALSE)

# Nombres de los atributos
names(datosAdult) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hour-per-week","native-country","income")

# Cargamos el fichero de datos en la variable rows
rows=dim(datosAdult)[1]

# Verificamos la estructura del conjunto de datos
str(datosAdult)

#Estadísticas básicas
summary(datosAdult)
```

#### Tratamos con los valores vacios o no existentes del dataset

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas de valores vacíos
datosAdult <- na_if(datosAdult, "?")
colSums(is.na(datosAdult))
```

#### Transformamos el atributo workclass para adaptarlo en un estudio posterior

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se revisa los tipos de datos de todos los atributos del dataset
sapply(datosAdult, class)

# Convertimos la variable workclass a categórica
datosAdult$workclass <- as.factor(datosAdult$workclass)

# Vemos la distribución de la variable workclass
table(datosAdult$workclass)
```
#### Aplicamos discretización a varios atributos del dataset

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Añadimos una variable nueva a los datos. Este valor es las horas trabajadas por semana discretizada con un método simple de intervalos de igual amplitud.
# Vemos cómo se distribuyen los valores
summary(datosAdult[,"hour-per-week"])

# Discretizamos las horas trabajadas
datosAdult["horas_trabajadas"] <- cut(datosAdult$`hour-per-week`, breaks = c(0,40,80,100), labels = c("0-40", "41-80", "81-100"))

# Discretizamos la variable age y creamos una nueva variable discreta segmento_edad
datosAdult["segmento_edad"] <- cut(datosAdult$age, breaks = c(0,20,30,40,50,60,90), labels = c("0-20", "21-30", "31-40", "41-50","51-60","61-90"))

# Discretizamos paises por continentes
datosAdult$Continente[datosAdult$`native-country` %in% c("England", "France", "Germany", "Greece", "Holand-Netherlands", "Hungary", "Ireland", "Italy", "Poland", "Portugal", "Scotland", "Yugoslavia")] = "Europa"
datosAdult$Continente[datosAdult$`native-country` %in% c("United-States", "Canada", "Puerto-Rico", "Nicaragua", "Guatemala", "Haiti", "Honduras", "Jamaica", "Trinidad&Tobago")] = "North-America"
datosAdult$Continente[datosAdult$`native-country` %in% c("China", "Cambodia", "Hong", "Philippines", "Taiwan", "Thailand", "Iran", "Japan", "Laos", "Vietnam", "India")] = "Asia"
datosAdult$Continente[datosAdult$`native-country` %in% c("Columbia", "Peru", "Ecuador", "Cuba", "El-Salvador", "Mexico", "Dominican-Republic")] = "Latin-America"
datosAdult$Continente[is.na(datosAdult$`native-country`)] <- "Desconocido"

# Observamos los datos discretizados.
head(datosAdult)

# Vemos como se agrupan los datos.
plot(datosAdult$horas_trabajadas)

# Vemos como se agrupan los datos por segmentos de edad
plot(datosAdult$segmento_edad)
```

#### Creamos un nuevo indicador a partir de los atributos **marital-status** y **relationship**

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Creamos una nueva variable en base al estado civil y relación
datosAdult$`Marital-Status-Relationship` <- paste(datosAdult$`marital-status`, datosAdult$relationship, sep = ' / ')
```


#### Procesos de análisis del conjunto de datos y conclusiones

Se pueden analizar varias relaciones de variables, ya que el dataset contiene 14 variables que influyen en los ingresos. La relación se la analizará entre los atributos más destacados y los ingresos (income)

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "sex" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=sex, fill=income))+geom_bar()

# Visualizamos la relación entre las variables "workclass" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=workclass, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Income en función del atributo workclass
ggplot(data=datosAdult[1:rows,],aes(x=workclass, fill=income))+geom_bar(position = "fill") + ylab("Frecuencia") + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Visualizamos la relación entre las variables "occupation" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=occupation, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Visualizamos la relación entre las variables "education" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=education, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Visualizamos la relación entre horas trabajadas e ingresos
ggplot(data=datosAdult[1:rows,],aes(x=horas_trabajadas, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

```


Las conclusiones al analizar estos gráficos son:
 
- En el primer gráfico, donde se analiza como la variable sex influye en los ingresos, vemos que el número de hombres con ingresos por encima de los 50K es aproximadamente 5 veces mayor que el número de mujeres. Asi mísmo esto se ve influenciado ya que en el dataset el número de varones analizados es 2 veces el número de mujeres.

- En el gráfico entre las clase de trabajo que realiza cada individuo, vemos que el mayor número corresponde al sector privado, llegando a sobrepasar por 10 el segundo número más alto analizado (self-amp-not-inc).

- Basta con analizar estos dos gráficos para darnos cuenta que el porcentaje de ingresos por debajo o igual (<=) a 50K es mayor a los que perciben unos ingresos superiores a 50K.

- Para el tercer gráfico vemos los porcentajes de ingresos superiores o inferiores a 50K por clase de trabajo. La clase **Self-emp-inc** es la que contiene una mayor frecuencia de personas que anualmente pueden superar los 50K, para conocer el porcentaje exacto, ejecutamos el siguiente fragmento de código:


```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(datosAdult[1:rows,]$workclass, datosAdult[1:rows,]$income)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

Vemos, entonces que la probabilidad generar unos ingresos anuales superiores a 50K es del 55.73% para la clase Self-emp-inc.

- Vemos que en el grafico donde analizamos las ocupaciones de cada uno hay una distribución no uniforme. Las ocupaciones que destacan por sus bajos ingresos son los que se dedican a labores privadas en el hogar, personal de aseo, los operativos de maquinarias y los que se dedican a otros servicios. Por el contrarios la ocupación que registra ingresos por encima de los 50K son los cargos ejecutvos gerenciales y los que cuentan con alguna profesión especializada.

- Otra variable importante a analizar y que influye demasiado es el grado de educación alcanzado. En el gráfico entre la educación y los ingresos, concluimos que definitivamente personas con títulos universitarios, como el caso de grado, masters y doctorados perciben ingresos superiores.

- En el último gráfico analizado hasta aquí visualizamos los ingresos contra la variable discretizada horas_trabajadas. Sabemos que en promedio a nivel mundial el estandar de horas laborales por semana son 40. En este caso vemos que más de 20K de estas personas tienen esta carga laboral semanalmente. Sin embargo también hay un gran número de personas que trabajan más de 40 horas semanales y lo curioso es que el número de personas con ingresos superiores a 50K es similar al de las que trabajan menos de 40 horas, a pesar de que la primera categoria (0-40h) tiene el más del doble de personas analizadas que la segunda categoría (41-80). Se concluye sin dura que es un factor determinante al momento de generar más ingresos el número de horas trabajadas a la semana.

Ahora vamos a analizar los ingresos en función de otras variables de índole social que en apariencia no son un factor clave para garantizar ingresos altos. Veamos que podemos concluir de estas relaciones.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la relación entre las variables "relationship" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=relationship, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Visualizamos la relación entre las variables "race" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=race, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Visualizamos la relación entre las variables "Continente" y "income"
ggplot(data=datosAdult[1:rows,],aes(x=`Continente`, fill=income))+geom_bar() + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Las conclusiones que podemos extraer son: 

- En la primera gráfica, vemos que los hombres casados son un gran número de personas que reciben ingresos altos. Aunque el número de mujeres casadas es muy inferior al de hombres, vemos que en porcentajes es similar al de hombres. Se concluye que es un factor considerable ser casado para generar más ingresos anuales superiores a 50K.

- En las 2 últimas gráficas donde se analiza el origen racial y el continente de las personas censadas, vemos que al ser mayoritariamente blanca y encontrarse la gran mayoría de personas censadas en Estados Unidos, podría generar una conclusión sesgada respecto a si la variable **race** y **Continente** es un factor social determinante para analizar el nivel de ingresos.

#### Se analiza la relación entre 3 variables para poder profundizar más en las conclusiones obtenidas previamente

Veamos ahora 2 gráficos de frecuencias donde podemos trabajar con 3 variables: segmento_edad, Income y Workclass para el primero y ocupación, ingresos y la variable discretizada segmento_edad.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Ahora, podemos dividir el gráfico de Ocupación por la variable workclass:
ggplot(data = datosAdult[1:rows,],aes(x=segmento_edad, fill=income))+geom_bar(position="fill")+facet_wrap(~workclass) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Graficamos la relación ocupación y segmento de edad en los ingresos anuales
ggplot(data = datosAdult[1:rows,],aes(x=occupation, fill=income))+geom_bar(position="fill")+facet_wrap(~segmento_edad) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

En esta última sección concluimos que: 

- Al analizar la primera gráfica se puede concluir que en casi todas las clases de trabajo, luego de cumplidos los 40 años, la probabilidad de ganar más de 50K anualmente es superior en comparación con las personas censadas más jóvenes (<40). Esto se confirma con el segundo gráfico, donde un alto porcentaje desempeñan cargos directivos entre los 40 y 60. 

- Un dato curioso es que todos los censados que pertenecen a las fuerzas armadas anualmente reciben ingresos superiores a 50K, seguramente se deba a los altos rangos en la institución que se alcanzan entre los 40 y 50.

#### Información adicional

Para realizar esta PEC se ha consultado las siguiente fuentes:

- Actividad 4, limpieza del conjunto de datos con R. Contenido de la carpeta compartida en Google Drive de la asignatura.
- Información adicional sobre el dataset en el siguiente enlace: http://archive.ics.uci.edu/ml/datasets/Adult. Fue de ayuda saber los siguiente:

* La extración de datos fue hecha por Barry Becker de la base de datos del censo de 1994. Los filtros aplicados sobre los registros son las siguiente condiciones: **((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))**

* La tarea de predicción fue para determinar si una persona hace más de $50.000 en un año.


***
# Rúbrica
***
Pregunta Concepto Peso en la nota final

1ª	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1ª	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1b	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1b	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

1c	Se acierta al identificar el tipo de problema que presenta el caso. 5%

1c	La explicación proporcionada es correcta. La justificación y argumentación está suficientemente elaborada. 5%

2 Se carga la base de datos, se visualiza su estructura y se explican los hechos básicos. 5%

2 Se estudia si existen atributos vacíos, y si es el caso, se adoptan medidas para tratar estos atributos. 2.5%

2 Se transforma algún atributo para adaptarlo en un estudio posterior. 2.5%

2 Se realiza alguna discretitzación de algún atributo. 2.5%

2 Se crea un indicador nuevo a partido otros atributos 2.5%

2 Se analizan los datos de forma visual y se extraen conclusiones tangibles. Hay que elaborar un discurso coherente y con conclusiones claras. 35%

2 Se trata en profundidad algún otro aspecto respecto a los datos presentado en el módulo 2 15%

2 Se ha buscado información adicional, se ha incluido en el documento de respuesta y las fuentes se han citado correctamente 5%